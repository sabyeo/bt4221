{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sabrina/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sabrina/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# for data analytics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "# for visualizations\n",
    "#import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# for data preparation\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "\n",
    "# imblean provides tools for us to deal with imbalanced class sizes\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# # For entropy computation\n",
    "# from pyitlib import discrete_random_variable as drv\n",
    "\n",
    "from scipy import stats\n",
    "import missingno\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# TEXT EDA\n",
    "# from wordcloud import WordCloud\n",
    "\n",
    "# import spacy\n",
    "# from spacy.lang.en.stop_words import STOP_WORDS\n",
    "# from spacy.lang.en import English\n",
    "\n",
    "#import matplotlib.pyplot as plt; plt.rcParams['figure.dpi'] = 100\n",
    "#import matplotlib.gridspec as gridspec\n",
    "#import seaborn as sns; sns.set()\n",
    "import ast\n",
    "\n",
    "from datetime import date, time, datetime\n",
    "import calendar\n",
    "\n",
    "import pandas as pd\n",
    "import emoji\n",
    "import regex as re\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import PorterStemmer\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file():\n",
    "    full_data = pd.DataFrame()\n",
    "    for file in os.listdir('../scrape/restaurant-data'):\n",
    "        if 'compiled' in file:\n",
    "            data = pd.read_csv(f'../scrape/restaurant-data/{file}', index_col = 0)\n",
    "            full_data = full_data.append(data)\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = read_file()\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. reviews: 28731\n",
      "No. restaurants: 863\n"
     ]
    }
   ],
   "source": [
    "# Total Number of restaurant reviews\n",
    "print(f'No. reviews: {len(data)}')\n",
    "# Number of restaurants with reviews\n",
    "num = len(data['url'].unique())\n",
    "print(f'No. restaurants: {num}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Cost Column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>price</th>\n",
       "      <th>categories</th>\n",
       "      <th>review</th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.burpple.com/bedok-85-market?bp_ref...</td>\n",
       "      <td>85 Fengshan Centre</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>~$5/pax</td>\n",
       "      <td>['Hawker Food', 'Supper', 'Cheap &amp; Good']</td>\n",
       "      <td>\\nFish Ball Minced Meat Noodle\\nFishball, meat...</td>\n",
       "      <td>Triffany Lim</td>\n",
       "      <td>21m ago</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.burpple.com/bedok-85-market?bp_ref...</td>\n",
       "      <td>85 Fengshan Centre</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>~$5/pax</td>\n",
       "      <td>['Hawker Food', 'Supper', 'Cheap &amp; Good']</td>\n",
       "      <td>\\nOrh lua\\nThere are a couple of stores, but g...</td>\n",
       "      <td>Ally Tan</td>\n",
       "      <td>Jul 30 at 4:12pm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.burpple.com/bedok-85-market?bp_ref...</td>\n",
       "      <td>85 Fengshan Centre</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>~$5/pax</td>\n",
       "      <td>['Hawker Food', 'Supper', 'Cheap &amp; Good']</td>\n",
       "      <td>\\nPeanut sauce was ace\\nI love a good satay pe...</td>\n",
       "      <td>Ally Tan</td>\n",
       "      <td>Jul 30 at 4:10pm</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url                name  \\\n",
       "0  https://www.burpple.com/bedok-85-market?bp_ref...  85 Fengshan Centre   \n",
       "1  https://www.burpple.com/bedok-85-market?bp_ref...  85 Fengshan Centre   \n",
       "2  https://www.burpple.com/bedok-85-market?bp_ref...  85 Fengshan Centre   \n",
       "\n",
       "  neighbourhood    price                                 categories  \\\n",
       "0         Bedok  ~$5/pax  ['Hawker Food', 'Supper', 'Cheap & Good']   \n",
       "1         Bedok  ~$5/pax  ['Hawker Food', 'Supper', 'Cheap & Good']   \n",
       "2         Bedok  ~$5/pax  ['Hawker Food', 'Supper', 'Cheap & Good']   \n",
       "\n",
       "                                              review          user  \\\n",
       "0  \\nFish Ball Minced Meat Noodle\\nFishball, meat...  Triffany Lim   \n",
       "1  \\nOrh lua\\nThere are a couple of stores, but g...      Ally Tan   \n",
       "2  \\nPeanut sauce was ace\\nI love a good satay pe...      Ally Tan   \n",
       "\n",
       "               date  cleaned_price  \n",
       "0           21m ago            5.0  \n",
       "1  Jul 30 at 4:12pm            5.0  \n",
       "2  Jul 30 at 4:10pm            5.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['cleaned_price'] = data['price'].apply(lambda x: int(x.split('/')[0].replace('~$','')) if '$' in x else np.nan)\n",
    "data.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {'Steak':['Western'], \n",
    " 'Cocktails':['Alcohol','Drinks'], \n",
    " 'Great View': ['Good Environment'], \n",
    " 'Sushi':['Japanese'], \n",
    " 'Ramen':['Japanese','Noodles'], \n",
    " 'Islandwide Delivery':['Convenient'], \n",
    " 'Craft Beer':['Drinks','Alcohol'], \n",
    " '1 For 1 Deals':['Value'],\n",
    " 'Teppanyaki':['Japanese'], \n",
    " 'Sustainable Dining on Beyond':['Sustainable'], \n",
    " 'Vegan friendly':['Sustainable'], \n",
    " 'Kopitiam':['Local Delights'], \n",
    " 'Char Kway Teow':['Local Delights','Noodles','Chinese'], \n",
    " 'Taiwanese':['Chinese'], \n",
    " 'Waffles':['Desserts'], \n",
    " 'Zi Char':['Local Delights','Chinese'], \n",
    " 'Fruit Tea':['Drinks'], \n",
    " 'Pasta':['Western','Noodles'], \n",
    " 'Vouchers':['Value'], \n",
    " 'Chirashi':['Japanese'], \n",
    " 'Bars':['Alcohol','Drinks'], \n",
    " 'Burpple Beyond Deals üí∞':['Value'], \n",
    " 'BITES':['Bites'],\n",
    " 'Burpple Guides':['Recommended'],\n",
    " 'Michelin Guide Singapore 2018':['Recommended'],\n",
    "'Grill & BBQ':['Western','BBQ'], \n",
    "'Bread & Pastries':['Desserts','High Tea', 'Breakfast & Brunch'], \n",
    " 'Vegetarian friendly':['Sustainable'], \n",
    " 'Cheap & Good':['Value'], \n",
    " 'Mediterranean':['European'], \n",
    " 'Middle Eastern': ['European'],\n",
    " 'Michelin Guide Singapore 2017':['Recommended'], \n",
    " 'Hawker Food':['Local Delights'], \n",
    " 'Ice Cream & Yoghurt':['Desserts'], \n",
    " 'Cafes & Coffee':['Desserts','High Tea', 'Breakfast & Brunch'], \n",
    " 'Interesting':['Good Environment'],\n",
    "'Dinner with Drinks':['Drinks'], \n",
    "'Bak Kut Teh':['Local Delights', 'Chinese'],\n",
    "'Burgers':['Western'],\n",
    "'Korean Desserts': ['Desserts','Korean'],\n",
    " 'Vegetarian':['Sustainable'], \n",
    " 'Nasi Lemak':['South East Asian','Local Delights'], \n",
    " 'Salads':['Western'], \n",
    "'TAKEAWAY OPTION':['Convenient'],\n",
    "'Delivery':['Convenient'], \n",
    "'Sandwiches':['High Tea', 'Breakfast & Brunch', 'Western'], \n",
    "'Pizza':['Western'],\n",
    "'Vegan':['Sustainable'], \n",
    "'Dim Sum':['Chinese'], \n",
    "'Chicken Rice':['Local Delights','Chinese'], \n",
    "'Fried Chicken':['Korean', 'Western', 'Bites','Fast Food'], \n",
    "'Korean BBQ':['Korean','BBQ'],\n",
    "'Filipino Local Delights':['Filipino'], \n",
    "'Cakes':['Desserts','High Tea'], \n",
    "'Michelin Guide Singapore 2019':['Recommended'],\n",
    " 'Korean Fried Chicken':['Korean','Bites','Fast Food'], \n",
    "'Hot Pot': ['Chinese', 'Rainy Day Comforts'], \n",
    "'Soup': ['Rainy Day Comforts'],\n",
    "'Late Night':['Supper'],\n",
    " 'Bubble Tea':['Drinks'],\n",
    " 'BEYOND': ['Recommended', 'Value'],\n",
    " 'Argentinian':['European'],\n",
    " 'Filipino Local Delights': ['South East Asian'],\n",
    " 'Indonesian': ['South East Asian'],\n",
    " 'Malay': ['South East Asian'],\n",
    " 'Vietnamese':['South East Asian'],\n",
    " 'Peranakan': ['South East Asian'],\n",
    " 'Thai': ['South East Asian'],\n",
    " 'Greek':['European'],\n",
    " 'Russian': ['European'],\n",
    " 'Turkish': ['European'],\n",
    " 'Mexican': ['European'],\n",
    " 'Spanish': ['European'],\n",
    " 'Newly Opened': ['Novel'],\n",
    " 'Hidden Gem':['Novel'],\n",
    " 'French': ['European'],\n",
    " 'Italian': ['European'],\n",
    " 'Kid Friendly': ['Accessible'],\n",
    " 'Pet-Friendly': ['Accessible'],\n",
    " 'Good For Groups': ['Accessible']\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find unique categories \n",
    "def find_unique_categories(category_col_name, data):\n",
    "    all_categories = []\n",
    "    for categories in data[category_col_name]:\n",
    "        try:\n",
    "            all_categories.extend(ast.literal_eval(categories))\n",
    "        except:\n",
    "            all_categories.extend(categories)\n",
    "    print(f'Num of Categories:{len(set(all_categories))}')\n",
    "    for i in set(all_categories):\n",
    "        print(i)\n",
    "    return list(set(all_categories))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Categories:101\n",
      "1 For 1 Deals\n",
      "Bars\n",
      "Great View\n",
      "Buffets\n",
      "Michelin Guide Singapore 2019\n",
      "Newly Opened\n",
      "Burpple Beyond Deals üí∞\n",
      "Vegan friendly\n",
      "Local Delights\n",
      "Indonesian\n",
      "Salads\n",
      "Mediterranean\n",
      "Bites\n",
      "Michelin Guide Singapore 2017\n",
      "Burgers\n",
      "Seafood\n",
      "Sushi\n",
      "Hawker Food\n",
      "Western\n",
      "Italian\n",
      "BEYOND\n",
      "Healthy\n",
      "TAKEAWAY OPTION\n",
      "Waffles\n",
      "Korean Desserts\n",
      "Cheap & Good\n",
      "Sandwiches\n",
      "Mexican\n",
      "Desserts\n",
      "Argentinian\n",
      "Cafes & Coffee\n",
      "Fruit Tea\n",
      "Spanish\n",
      "Ramen\n",
      "Breakfast & Brunch\n",
      "Filipino Local Delights\n",
      "Soup\n",
      "Cocktails\n",
      "Pizza\n",
      "Cakes\n",
      "Thai\n",
      "Sustainable Dining on Beyond\n",
      "Date Night\n",
      "BBQ\n",
      "Zi Char\n",
      "Bubble Tea\n",
      "Burpple Guides\n",
      "Russian\n",
      "Bread & Pastries\n",
      "Vietnamese\n",
      "Grill & BBQ\n",
      "BITES\n",
      "Halal\n",
      "Vouchers\n",
      "Pasta\n",
      "Vegan\n",
      "Korean BBQ\n",
      "High Tea\n",
      "European\n",
      "Bak Kut Teh\n",
      "Good For Groups\n",
      "Ice Cream & Yoghurt\n",
      "Teppanyaki\n",
      "Rainy Day Comforts\n",
      "Noodles\n",
      "Supper\n",
      "Steak\n",
      "Dinner with Drinks\n",
      "Fast Food\n",
      "Hidden Gem\n",
      "French\n",
      "Vegetarian\n",
      "Korean\n",
      "Islandwide Delivery\n",
      "Nasi Lemak\n",
      "Chinese\n",
      "Fried Chicken\n",
      "Hot Pot\n",
      "Taiwanese\n",
      "Malay\n",
      "Dim Sum\n",
      "Kid Friendly\n",
      "Late Night\n",
      "Interesting\n",
      "Peranakan\n",
      "Pet-Friendly\n",
      "Chirashi\n",
      "Korean Fried Chicken\n",
      "Vegetarian friendly\n",
      "Chicken Rice\n",
      "Fine Dining\n",
      "Delivery\n",
      "Craft Beer\n",
      "Middle Eastern\n",
      "Turkish\n",
      "Indian\n",
      "Japanese\n",
      "Char Kway Teow\n",
      "Michelin Guide Singapore 2018\n",
      "Kopitiam\n",
      "Greek\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1 For 1 Deals',\n",
       " 'Bars',\n",
       " 'Great View',\n",
       " 'Buffets',\n",
       " 'Michelin Guide Singapore 2019',\n",
       " 'Newly Opened',\n",
       " 'Burpple Beyond Deals üí∞',\n",
       " 'Vegan friendly',\n",
       " 'Local Delights',\n",
       " 'Indonesian',\n",
       " 'Salads',\n",
       " 'Mediterranean',\n",
       " 'Bites',\n",
       " 'Michelin Guide Singapore 2017',\n",
       " 'Burgers',\n",
       " 'Seafood',\n",
       " 'Sushi',\n",
       " 'Hawker Food',\n",
       " 'Western',\n",
       " 'Italian',\n",
       " 'BEYOND',\n",
       " 'Healthy',\n",
       " 'TAKEAWAY OPTION',\n",
       " 'Waffles',\n",
       " 'Korean Desserts',\n",
       " 'Cheap & Good',\n",
       " 'Sandwiches',\n",
       " 'Mexican',\n",
       " 'Desserts',\n",
       " 'Argentinian',\n",
       " 'Cafes & Coffee',\n",
       " 'Fruit Tea',\n",
       " 'Spanish',\n",
       " 'Ramen',\n",
       " 'Breakfast & Brunch',\n",
       " 'Filipino Local Delights',\n",
       " 'Soup',\n",
       " 'Cocktails',\n",
       " 'Pizza',\n",
       " 'Cakes',\n",
       " 'Thai',\n",
       " 'Sustainable Dining on Beyond',\n",
       " 'Date Night',\n",
       " 'BBQ',\n",
       " 'Zi Char',\n",
       " 'Bubble Tea',\n",
       " 'Burpple Guides',\n",
       " 'Russian',\n",
       " 'Bread & Pastries',\n",
       " 'Vietnamese',\n",
       " 'Grill & BBQ',\n",
       " 'BITES',\n",
       " 'Halal',\n",
       " 'Vouchers',\n",
       " 'Pasta',\n",
       " 'Vegan',\n",
       " 'Korean BBQ',\n",
       " 'High Tea',\n",
       " 'European',\n",
       " 'Bak Kut Teh',\n",
       " 'Good For Groups',\n",
       " 'Ice Cream & Yoghurt',\n",
       " 'Teppanyaki',\n",
       " 'Rainy Day Comforts',\n",
       " 'Noodles',\n",
       " 'Supper',\n",
       " 'Steak',\n",
       " 'Dinner with Drinks',\n",
       " 'Fast Food',\n",
       " 'Hidden Gem',\n",
       " 'French',\n",
       " 'Vegetarian',\n",
       " 'Korean',\n",
       " 'Islandwide Delivery',\n",
       " 'Nasi Lemak',\n",
       " 'Chinese',\n",
       " 'Fried Chicken',\n",
       " 'Hot Pot',\n",
       " 'Taiwanese',\n",
       " 'Malay',\n",
       " 'Dim Sum',\n",
       " 'Kid Friendly',\n",
       " 'Late Night',\n",
       " 'Interesting',\n",
       " 'Peranakan',\n",
       " 'Pet-Friendly',\n",
       " 'Chirashi',\n",
       " 'Korean Fried Chicken',\n",
       " 'Vegetarian friendly',\n",
       " 'Chicken Rice',\n",
       " 'Fine Dining',\n",
       " 'Delivery',\n",
       " 'Craft Beer',\n",
       " 'Middle Eastern',\n",
       " 'Turkish',\n",
       " 'Indian',\n",
       " 'Japanese',\n",
       " 'Char Kway Teow',\n",
       " 'Michelin Guide Singapore 2018',\n",
       " 'Kopitiam',\n",
       " 'Greek']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_unique_categories('categories', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map categories\n",
    "all_new_categories = []\n",
    "for idx, row in data.iterrows():\n",
    "    categories = ast.literal_eval(row['categories'])\n",
    "    new_categories = []\n",
    "    for category in categories:\n",
    "        if category.strip() in category_mapping.keys():\n",
    "            new_categories.extend(category_mapping[category.strip()])\n",
    "        else:\n",
    "            new_categories.append(category)\n",
    "    all_new_categories.append(new_categories)\n",
    "\n",
    "data['cleaned_categories'] = all_new_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Categories:32\n",
      "Chinese\n",
      "Novel\n",
      "Buffets\n",
      "Alcohol\n",
      "Drinks\n",
      "Good Environment\n",
      "Desserts\n",
      "Breakfast & Brunch\n",
      "Recommended\n",
      "Accessible\n",
      "High Tea\n",
      "South East Asian\n",
      "Convenient\n",
      "European\n",
      "Local Delights\n",
      "Bites\n",
      "Fine Dining\n",
      "Date Night\n",
      "Rainy Day Comforts\n",
      "BBQ\n",
      "Seafood\n",
      "Indian\n",
      "Noodles\n",
      "Western\n",
      "Supper\n",
      "Japanese\n",
      "Healthy\n",
      "Fast Food\n",
      "Value\n",
      "Halal\n",
      "Korean\n",
      "Sustainable\n"
     ]
    }
   ],
   "source": [
    "# find unique categories after mapping\n",
    "list_cleaned_categories = find_unique_categories('cleaned_categories', data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decontraction\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    phrase = re.sub(r\"didn\\'t\", \"did not\", phrase)\n",
    "    phrase = re.sub(r\"don\\'t\", \"do not\", phrase)\n",
    "    phrase = re.sub(r\"o\\'clock\", \"clock\", phrase)\n",
    "    phrase = re.sub(r\"couldn\\'t\", \"could not\", phrase)\n",
    "    phrase = re.sub(r\"that\\'s\", \"that is\", phrase)       \n",
    "    phrase = re.sub(r\"go-around\", \"go around\", phrase)  \n",
    "    # general\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    #phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(df):\n",
    "    text_list = df['review']\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    new_stopwords = ['address', 'note', 'tel', 'website', 'open', 'burpple']\n",
    "    add_stopwords = set(['br', 'the', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\\\n",
    "        \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', \\\n",
    "        'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their',\\\n",
    "        'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', \\\n",
    "        'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', \\\n",
    "        'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', \\\n",
    "        'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after',\\\n",
    "        'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further',\\\n",
    "        'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\\\n",
    "        'most', 'other', 'some', 'such', 'only', 'own', 'same', 'so', 'than', 'too', 'very', \\\n",
    "        's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', \\\n",
    "        've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn',\\\n",
    "        \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn',\\\n",
    "        \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", \\\n",
    "        'won', \"won't\", 'wouldn', \"wouldn't\"])\n",
    "    add_stopwords_2 =  ['n','s','m','i','1','2','3','4','5','6','7','8','9','10','one','two',\n",
    "        'it','in','ve','well','could','would','really','also','even',\n",
    "        'alway','always','still','never','much','thing','yet',\n",
    "        'said','asked','did','go','got','do','make','know','think','come','going',\n",
    "        'put','went','seem','order','ordered','give','eat','make','get']\n",
    "    \n",
    "    stopwords.extend(new_stopwords)\n",
    "    stopwords.extend(add_stopwords)\n",
    "    stopwords.extend(add_stopwords_2)\n",
    "\n",
    "    ### FOR SENTIMENT ANALYSIS< UNCOMMENT THIS\n",
    "    # not_stopwords = {'no','nor','not'} \n",
    "    # stopwords = set([word for word in stopwords if word not in not_stopwords])\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    ps = PorterStemmer()\n",
    "    cleaned_text_list = []\n",
    "    count = 0\n",
    "    for text in text_list:\n",
    "\n",
    "        # lower case\n",
    "        text = text.lower()\n",
    "\n",
    "        # demojize    \n",
    "        text = emoji.demojize(text)\n",
    "\n",
    "        # remove headers\n",
    "        text = ' '.join(text.split('\\n')[2:])\n",
    "\n",
    "        # remove location (pushpin or location:)\n",
    "        text = text.split('round_pushpin')[0]\n",
    "        text = text.split('location:')[0]\n",
    "    \n",
    "        # clean punctuation\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "        # tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "\n",
    "        # remove stopwords and urls\n",
    "        tokens = [word for word in tokens if word not in stopwords]\n",
    "        tokens = [word for word in tokens if 'http' not in word]\n",
    "        tokens = [word for word in tokens if 'www' not in word]\n",
    "\n",
    "        # decontraction\n",
    "        tokens = [decontracted(word) for word in tokens]\n",
    "\n",
    "        # translate to english\n",
    "        # text = GoogleTranslator(source='auto', target='en').translate(text)\n",
    "    \n",
    "        # POS tagging\n",
    "        tokens = [nltk.pos_tag([word]) for word in tokens]\n",
    "\n",
    "        # lemmatization\n",
    "        tokens = [lemmatizer.lemmatize(word[0][0], get_wordnet_pos(word[0][1])) \n",
    "            if get_wordnet_pos(word[0][1])!=None else lemmatizer.lemmatize(word[0][0]) for word in tokens]\n",
    "    \n",
    "        # concatenate tokens back\n",
    "        cleaned_text = \" \".join(tokens)\n",
    "        cleaned_text_list.append(cleaned_text)\n",
    "\n",
    "        if count%1000 == 0:\n",
    "            print(count)\n",
    "        count+=1\n",
    "\n",
    "    df['cleaned_text'] = cleaned_text_list\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n"
     ]
    }
   ],
   "source": [
    "cleaned_df = clean_text(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace empty strings with np.nan\n",
    "cleaned_df = cleaned_df.replace(r'^\\s*$', np.nan, regex=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>price</th>\n",
       "      <th>categories</th>\n",
       "      <th>review</th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_price</th>\n",
       "      <th>cleaned_categories</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>28731.0</td>\n",
       "      <td>28731.0</td>\n",
       "      <td>28708</td>\n",
       "      <td>28731.0</td>\n",
       "      <td>28731.0</td>\n",
       "      <td>28731.0</td>\n",
       "      <td>28731.0</td>\n",
       "      <td>28731.0</td>\n",
       "      <td>28302</td>\n",
       "      <td>28731.0</td>\n",
       "      <td>28503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>228</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           url     name  neighbourhood    price  categories   review     user  \\\n",
       "False  28731.0  28731.0          28708  28731.0     28731.0  28731.0  28731.0   \n",
       "True       NaN      NaN             23      NaN         NaN      NaN      NaN   \n",
       "\n",
       "          date  cleaned_price  cleaned_categories  cleaned_text  \n",
       "False  28731.0          28302             28731.0         28503  \n",
       "True       NaN            429                 NaN           228  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there is any null value\n",
    "cleaned_df.isna().apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 89 reviews have no neighbourhood. Thus, we drop these reviews.\n",
    "cleaned_data = cleaned_df[~cleaned_df['neighbourhood'].isna()]\n",
    "\n",
    "# 1781 reviews have no price. Thus, we drop these reviews.\n",
    "cleaned_data = cleaned_data[~cleaned_data['cleaned_price'].isna()]\n",
    "\n",
    "# 2 reviews have no review text. Thus, we drop these reviews.\n",
    "cleaned_data = cleaned_data[~cleaned_data['cleaned_text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. reviews: 28075\n",
      "No. restaurants: 845\n"
     ]
    }
   ],
   "source": [
    "# Total Number of restaurant reviews\n",
    "print(f'No. reviews: {len(cleaned_data)}')\n",
    "# Number of restaurants with reviews\n",
    "num = len(cleaned_data['url'].unique())\n",
    "print(f'No. restaurants: {num}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Cat Variables to Binary Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Categories:32\n",
      "Chinese\n",
      "Novel\n",
      "Buffets\n",
      "Alcohol\n",
      "Drinks\n",
      "Good Environment\n",
      "Desserts\n",
      "Breakfast & Brunch\n",
      "Recommended\n",
      "Accessible\n",
      "High Tea\n",
      "South East Asian\n",
      "Convenient\n",
      "European\n",
      "Local Delights\n",
      "Bites\n",
      "Fine Dining\n",
      "Date Night\n",
      "Rainy Day Comforts\n",
      "BBQ\n",
      "Seafood\n",
      "Indian\n",
      "Noodles\n",
      "Western\n",
      "Supper\n",
      "Japanese\n",
      "Healthy\n",
      "Fast Food\n",
      "Value\n",
      "Halal\n",
      "Korean\n",
      "Sustainable\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Chinese',\n",
       " 'Novel',\n",
       " 'Buffets',\n",
       " 'Alcohol',\n",
       " 'Drinks',\n",
       " 'Good Environment',\n",
       " 'Desserts',\n",
       " 'Breakfast & Brunch',\n",
       " 'Recommended',\n",
       " 'Accessible',\n",
       " 'High Tea',\n",
       " 'South East Asian',\n",
       " 'Convenient',\n",
       " 'European',\n",
       " 'Local Delights',\n",
       " 'Bites',\n",
       " 'Fine Dining',\n",
       " 'Date Night',\n",
       " 'Rainy Day Comforts',\n",
       " 'BBQ',\n",
       " 'Seafood',\n",
       " 'Indian',\n",
       " 'Noodles',\n",
       " 'Western',\n",
       " 'Supper',\n",
       " 'Japanese',\n",
       " 'Healthy',\n",
       " 'Fast Food',\n",
       " 'Value',\n",
       " 'Halal',\n",
       " 'Korean',\n",
       " 'Sustainable']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_cleaned_categories = find_unique_categories('cleaned_categories', cleaned_data)\n",
    "list_cleaned_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# append empty columns with category names\n",
    "cleaned_data = cleaned_data.reindex(cleaned_data.columns.tolist() + list_cleaned_categories, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chinese\n",
      "Novel\n",
      "Buffets\n",
      "Alcohol\n",
      "Drinks\n",
      "Good Environment\n",
      "Desserts\n",
      "Breakfast & Brunch\n",
      "Recommended\n",
      "Accessible\n",
      "High Tea\n",
      "South East Asian\n",
      "Convenient\n",
      "European\n",
      "Local Delights\n",
      "Bites\n",
      "Fine Dining\n",
      "Date Night\n",
      "Rainy Day Comforts\n",
      "BBQ\n",
      "Seafood\n",
      "Indian\n",
      "Noodles\n",
      "Western\n",
      "Supper\n",
      "Japanese\n",
      "Healthy\n",
      "Fast Food\n",
      "Value\n",
      "Halal\n",
      "Korean\n",
      "Sustainable\n"
     ]
    }
   ],
   "source": [
    "for category in list_cleaned_categories:\n",
    "    print(category)\n",
    "    cleaned_data[category] = cleaned_data['cleaned_categories'].apply(lambda x: 1 if category in x else 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping Neighbourhoods to Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbourhood_to_region_mapping = pd.read_excel('neighbourhood_to_region_mapping.xlsx')\n",
    "neighbourhood_to_region_mapping['neighbourhood'] = neighbourhood_to_region_mapping['neighbourhood'].apply(lambda x: x.replace('\\xa0',''))\n",
    "neighbourhood_to_region_mapping = neighbourhood_to_region_mapping.set_index('neighbourhood').T.to_dict('records')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data['region'] = cleaned_data['neighbourhood'].apply(lambda x: neighbourhood_to_region_mapping[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>name</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>price</th>\n",
       "      <th>categories</th>\n",
       "      <th>review</th>\n",
       "      <th>user</th>\n",
       "      <th>date</th>\n",
       "      <th>cleaned_price</th>\n",
       "      <th>cleaned_categories</th>\n",
       "      <th>...</th>\n",
       "      <th>Western</th>\n",
       "      <th>Supper</th>\n",
       "      <th>Japanese</th>\n",
       "      <th>Healthy</th>\n",
       "      <th>Fast Food</th>\n",
       "      <th>Value</th>\n",
       "      <th>Halal</th>\n",
       "      <th>Korean</th>\n",
       "      <th>Sustainable</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.burpple.com/bedok-85-market?bp_ref...</td>\n",
       "      <td>85 Fengshan Centre</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>~$5/pax</td>\n",
       "      <td>['Hawker Food', 'Supper', 'Cheap &amp; Good']</td>\n",
       "      <td>\\nFish Ball Minced Meat Noodle\\nFishball, meat...</td>\n",
       "      <td>Triffany Lim</td>\n",
       "      <td>21m ago</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Local Delights, Supper, Value]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.burpple.com/bedok-85-market?bp_ref...</td>\n",
       "      <td>85 Fengshan Centre</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>~$5/pax</td>\n",
       "      <td>['Hawker Food', 'Supper', 'Cheap &amp; Good']</td>\n",
       "      <td>\\nOrh lua\\nThere are a couple of stores, but g...</td>\n",
       "      <td>Ally Tan</td>\n",
       "      <td>Jul 30 at 4:12pm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Local Delights, Supper, Value]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.burpple.com/bedok-85-market?bp_ref...</td>\n",
       "      <td>85 Fengshan Centre</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>~$5/pax</td>\n",
       "      <td>['Hawker Food', 'Supper', 'Cheap &amp; Good']</td>\n",
       "      <td>\\nPeanut sauce was ace\\nI love a good satay pe...</td>\n",
       "      <td>Ally Tan</td>\n",
       "      <td>Jul 30 at 4:10pm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Local Delights, Supper, Value]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.burpple.com/bedok-85-market?bp_ref...</td>\n",
       "      <td>85 Fengshan Centre</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>~$5/pax</td>\n",
       "      <td>['Hawker Food', 'Supper', 'Cheap &amp; Good']</td>\n",
       "      <td>\\nClassic BBQ wings\\nJuicy and tasty like it‚Äôs...</td>\n",
       "      <td>Ally Tan</td>\n",
       "      <td>Jul 30 at 4:09pm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Local Delights, Supper, Value]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.burpple.com/bedok-85-market?bp_ref...</td>\n",
       "      <td>85 Fengshan Centre</td>\n",
       "      <td>Bedok</td>\n",
       "      <td>~$5/pax</td>\n",
       "      <td>['Hawker Food', 'Supper', 'Cheap &amp; Good']</td>\n",
       "      <td>\\nBBQ stingray\\nIt was yummy but slight warnin...</td>\n",
       "      <td>Ally Tan</td>\n",
       "      <td>Jul 30 at 4:08pm</td>\n",
       "      <td>5.0</td>\n",
       "      <td>[Local Delights, Supper, Value]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>East</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://www.burpple.com/chui-huay-lim-teochew-...</td>\n",
       "      <td>Chui Huay Lim Teochew Cuisine</td>\n",
       "      <td>Newton</td>\n",
       "      <td>~$50/pax</td>\n",
       "      <td>['Chinese', 'Good For Groups']</td>\n",
       "      <td>\\nBento Box D  $13.80\\nÂ∑ùÊ§íÈõûÊü≥ | ÈÆÆËÖêÁ´πËù¶ÁêÉ | Ê∏ÖÁÇíË•øËò≠Ëä± | ...</td>\n",
       "      <td>K T</td>\n",
       "      <td>Oct 27, 2020</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[Chinese, Accessible]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://www.burpple.com/chui-huay-lim-teochew-...</td>\n",
       "      <td>Chui Huay Lim Teochew Cuisine</td>\n",
       "      <td>Newton</td>\n",
       "      <td>~$50/pax</td>\n",
       "      <td>['Chinese', 'Good For Groups']</td>\n",
       "      <td>\\nBento Box C  $11.80\\nÊôÆÂØßË±ÜÈÜ¨Ëµ∞Âú∞Èõû | ÈÆÆËèåÁø°Áø†Ë±ÜËÖê | ËíúËå∏ÁÇíÂõõ...</td>\n",
       "      <td>K T</td>\n",
       "      <td>Oct 26, 2020</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[Chinese, Accessible]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.burpple.com/chui-huay-lim-teochew-...</td>\n",
       "      <td>Chui Huay Lim Teochew Cuisine</td>\n",
       "      <td>Newton</td>\n",
       "      <td>~$50/pax</td>\n",
       "      <td>['Chinese', 'Good For Groups']</td>\n",
       "      <td>\\nBento Box B  $11.80\\nËíúÂ≠êË±ÜË±âÂáâÁìúÈªëË±¨Ê¢ÖËÇâ | È¶ôËèåÊâíË±ÜËÖê | ËíúËå∏...</td>\n",
       "      <td>K T</td>\n",
       "      <td>Oct 9, 2020</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[Chinese, Accessible]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.burpple.com/chui-huay-lim-teochew-...</td>\n",
       "      <td>Chui Huay Lim Teochew Cuisine</td>\n",
       "      <td>Newton</td>\n",
       "      <td>~$50/pax</td>\n",
       "      <td>['Chinese', 'Good For Groups']</td>\n",
       "      <td>\\nÊΩÆÂ∑ûÁ≥ú Bento A  $12.80\\nÈπµÈ¥®ÊãºË±ÜÂπ≤ | Â∑ùÊ§íÈõû | Ê¨ñËèúÂõõÂ≠£Ëãó| ËèúËÑØ...</td>\n",
       "      <td>K T</td>\n",
       "      <td>Oct 1, 2020</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[Chinese, Accessible]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>https://www.burpple.com/chui-huay-lim-teochew-...</td>\n",
       "      <td>Chui Huay Lim Teochew Cuisine</td>\n",
       "      <td>Newton</td>\n",
       "      <td>~$50/pax</td>\n",
       "      <td>['Chinese', 'Good For Groups']</td>\n",
       "      <td>\\nNgoh Hiang\\nSo good! Crispy exterior with a ...</td>\n",
       "      <td>Rachel Syj</td>\n",
       "      <td>Jan 17, 2020</td>\n",
       "      <td>50.0</td>\n",
       "      <td>[Chinese, Accessible]</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28075 rows √ó 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  url  \\\n",
       "0   https://www.burpple.com/bedok-85-market?bp_ref...   \n",
       "1   https://www.burpple.com/bedok-85-market?bp_ref...   \n",
       "2   https://www.burpple.com/bedok-85-market?bp_ref...   \n",
       "3   https://www.burpple.com/bedok-85-market?bp_ref...   \n",
       "4   https://www.burpple.com/bedok-85-market?bp_ref...   \n",
       "..                                                ...   \n",
       "14  https://www.burpple.com/chui-huay-lim-teochew-...   \n",
       "15  https://www.burpple.com/chui-huay-lim-teochew-...   \n",
       "16  https://www.burpple.com/chui-huay-lim-teochew-...   \n",
       "17  https://www.burpple.com/chui-huay-lim-teochew-...   \n",
       "30  https://www.burpple.com/chui-huay-lim-teochew-...   \n",
       "\n",
       "                             name neighbourhood     price  \\\n",
       "0              85 Fengshan Centre         Bedok   ~$5/pax   \n",
       "1              85 Fengshan Centre         Bedok   ~$5/pax   \n",
       "2              85 Fengshan Centre         Bedok   ~$5/pax   \n",
       "3              85 Fengshan Centre         Bedok   ~$5/pax   \n",
       "4              85 Fengshan Centre         Bedok   ~$5/pax   \n",
       "..                            ...           ...       ...   \n",
       "14  Chui Huay Lim Teochew Cuisine        Newton  ~$50/pax   \n",
       "15  Chui Huay Lim Teochew Cuisine        Newton  ~$50/pax   \n",
       "16  Chui Huay Lim Teochew Cuisine        Newton  ~$50/pax   \n",
       "17  Chui Huay Lim Teochew Cuisine        Newton  ~$50/pax   \n",
       "30  Chui Huay Lim Teochew Cuisine        Newton  ~$50/pax   \n",
       "\n",
       "                                   categories  \\\n",
       "0   ['Hawker Food', 'Supper', 'Cheap & Good']   \n",
       "1   ['Hawker Food', 'Supper', 'Cheap & Good']   \n",
       "2   ['Hawker Food', 'Supper', 'Cheap & Good']   \n",
       "3   ['Hawker Food', 'Supper', 'Cheap & Good']   \n",
       "4   ['Hawker Food', 'Supper', 'Cheap & Good']   \n",
       "..                                        ...   \n",
       "14             ['Chinese', 'Good For Groups']   \n",
       "15             ['Chinese', 'Good For Groups']   \n",
       "16             ['Chinese', 'Good For Groups']   \n",
       "17             ['Chinese', 'Good For Groups']   \n",
       "30             ['Chinese', 'Good For Groups']   \n",
       "\n",
       "                                               review          user  \\\n",
       "0   \\nFish Ball Minced Meat Noodle\\nFishball, meat...  Triffany Lim   \n",
       "1   \\nOrh lua\\nThere are a couple of stores, but g...      Ally Tan   \n",
       "2   \\nPeanut sauce was ace\\nI love a good satay pe...      Ally Tan   \n",
       "3   \\nClassic BBQ wings\\nJuicy and tasty like it‚Äôs...      Ally Tan   \n",
       "4   \\nBBQ stingray\\nIt was yummy but slight warnin...      Ally Tan   \n",
       "..                                                ...           ...   \n",
       "14  \\nBento Box D  $13.80\\nÂ∑ùÊ§íÈõûÊü≥ | ÈÆÆËÖêÁ´πËù¶ÁêÉ | Ê∏ÖÁÇíË•øËò≠Ëä± | ...           K T   \n",
       "15  \\nBento Box C  $11.80\\nÊôÆÂØßË±ÜÈÜ¨Ëµ∞Âú∞Èõû | ÈÆÆËèåÁø°Áø†Ë±ÜËÖê | ËíúËå∏ÁÇíÂõõ...           K T   \n",
       "16  \\nBento Box B  $11.80\\nËíúÂ≠êË±ÜË±âÂáâÁìúÈªëË±¨Ê¢ÖËÇâ | È¶ôËèåÊâíË±ÜËÖê | ËíúËå∏...           K T   \n",
       "17  \\nÊΩÆÂ∑ûÁ≥ú Bento A  $12.80\\nÈπµÈ¥®ÊãºË±ÜÂπ≤ | Â∑ùÊ§íÈõû | Ê¨ñËèúÂõõÂ≠£Ëãó| ËèúËÑØ...           K T   \n",
       "30  \\nNgoh Hiang\\nSo good! Crispy exterior with a ...    Rachel Syj   \n",
       "\n",
       "                                date  cleaned_price  \\\n",
       "0                            21m ago            5.0   \n",
       "1                   Jul 30 at 4:12pm            5.0   \n",
       "2                   Jul 30 at 4:10pm            5.0   \n",
       "3                   Jul 30 at 4:09pm            5.0   \n",
       "4                   Jul 30 at 4:08pm            5.0   \n",
       "..                               ...            ...   \n",
       "14            Oct 27, 2020                     50.0   \n",
       "15            Oct 26, 2020                     50.0   \n",
       "16             Oct 9, 2020                     50.0   \n",
       "17             Oct 1, 2020                     50.0   \n",
       "30            Jan 17, 2020                     50.0   \n",
       "\n",
       "                 cleaned_categories  ... Western  Supper  Japanese  Healthy  \\\n",
       "0   [Local Delights, Supper, Value]  ...       0       1         0        0   \n",
       "1   [Local Delights, Supper, Value]  ...       0       1         0        0   \n",
       "2   [Local Delights, Supper, Value]  ...       0       1         0        0   \n",
       "3   [Local Delights, Supper, Value]  ...       0       1         0        0   \n",
       "4   [Local Delights, Supper, Value]  ...       0       1         0        0   \n",
       "..                              ...  ...     ...     ...       ...      ...   \n",
       "14            [Chinese, Accessible]  ...       0       0         0        0   \n",
       "15            [Chinese, Accessible]  ...       0       0         0        0   \n",
       "16            [Chinese, Accessible]  ...       0       0         0        0   \n",
       "17            [Chinese, Accessible]  ...       0       0         0        0   \n",
       "30            [Chinese, Accessible]  ...       0       0         0        0   \n",
       "\n",
       "    Fast Food  Value  Halal  Korean  Sustainable   region  \n",
       "0           0      1      0       0            0     East  \n",
       "1           0      1      0       0            0     East  \n",
       "2           0      1      0       0            0     East  \n",
       "3           0      1      0       0            0     East  \n",
       "4           0      1      0       0            0     East  \n",
       "..        ...    ...    ...     ...          ...      ...  \n",
       "14          0      0      0       0            0  Central  \n",
       "15          0      0      0       0            0  Central  \n",
       "16          0      0      0       0            0  Central  \n",
       "17          0      0      0       0            0  Central  \n",
       "30          0      0      0       0            0  Central  \n",
       "\n",
       "[28075 rows x 44 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data.to_csv('cleaned_restaurant_reviews.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
