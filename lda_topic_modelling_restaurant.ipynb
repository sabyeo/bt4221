{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('scrape/restaurant-data/cleaned_restaurant_reviews.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_review_df = data[['url', 'cleaned_text']]\n",
    "restaurant_review_df = restaurant_review_df.groupby(['url'], as_index = False).agg({'cleaned_text': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "restaurant_review_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary\n",
    "docs = data['cleaned_text'] ###\n",
    "processed_docs = [d.split() for d in docs]\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term document frequency\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
    "                                       id2word=dictionary,\n",
    "                                       num_topics=10,\n",
    "                                       alpha=0.1, # document topic density. higher alpha, documents composed of more topics\n",
    "                                       eta=0.01, # topic word density. higher beta, topics composed of large number of words in the corpus\n",
    "                                       chunksize=100, # number of documents to consider at once\n",
    "                                       passes=10, # number of times to go through the entire corpus\n",
    "                                       random_state =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "lda_score = coherence_model_lda.get_coherence()\n",
    "lda_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(k):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k,\n",
    "                                           alpha=0.1, # document topic density. higher alpha, documents composed of more topics\n",
    "                                           eta=0.01, # topic word density. higher beta, topics composed of large number of words in the corpus\n",
    "                                           chunksize=100, # number of documents to consider at once\n",
    "                                           passes=10, # number of times to go through the entire corpus\n",
    "                                           random_state =100)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = {}\n",
    "# grid['Validation_Set'] = {}\n",
    "\n",
    "# # Topics range\n",
    "# min_topics = 2\n",
    "# max_topics = 11\n",
    "# step_size = 1\n",
    "# topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# # Alpha parameter\n",
    "# alpha = list(np.arange(0.01, 1, 0.3))\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# # Beta parameter\n",
    "# beta = list(np.arange(0.01, 1, 0.3))\n",
    "# beta.append('symmetric')\n",
    "\n",
    "\n",
    "# model_results = {\n",
    "#                  'Topics': [],\n",
    "#                  'Alpha': [],\n",
    "#                  'Beta': [],\n",
    "#                  'Coherence': []\n",
    "#                 }\n",
    "\n",
    "# # Can take a long time to run\n",
    "# if 1 == 1:\n",
    "#     pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)))\n",
    "    \n",
    "#     # iterate through number of topics\n",
    "#     for k in topics_range:\n",
    "#         # iterate through alpha values\n",
    "#         for a in alpha:\n",
    "#             # iterare through beta values\n",
    "#             for b in beta:\n",
    "#                 # get the coherence score for the given parameters\n",
    "#                 cv = compute_coherence_values(k=k, a=a, b=b)\n",
    "#                 # Save the model results\n",
    "#                 model_results['Topics'].append(k)\n",
    "#                 model_results['Alpha'].append(a)\n",
    "#                 model_results['Beta'].append(b)\n",
    "#                 model_results['Coherence'].append(cv)\n",
    "                \n",
    "#                 pbar.update(1)\n",
    "#     pd.DataFrame(model_results).to_csv('restaurant_lda_tuning_results.csv', index=False)\n",
    "#     pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through number of topics\n",
    "coherence_values = []\n",
    "topics_range = range(2,11,1)\n",
    "\n",
    "for k in topics_range:\n",
    "    value = compute_coherence_values(k)\n",
    "    print(k)\n",
    "    print(value)\n",
    "    coherence_values.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "plt.plot(topics_range, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()\n",
    "\n",
    "# choose num topics == 6 instead since 6 & 7 is stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal parameters\n",
    "num_topics = 6 ### CHANGE THIS\n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
    "                                        id2word=dictionary,\n",
    "                                        num_topics=num_topics,\n",
    "                                        alpha=0.1, # document topic density. higher alpha, documents composed of more topics\n",
    "                                        eta=0.01, # topic word density. higher beta, topics composed of large number of words in the corpus\n",
    "                                        chunksize=100, # number of documents to consider at once\n",
    "                                        passes=10, # number of times to go through the entire corpus\n",
    "                                        random_state =100)\n",
    "# Print the Keyword in the topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics \n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('ldavis_prepared_'+str(num_topics)+'_')\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, 'ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared\n",
    "\n",
    "### https://we1s.ucsb.edu/research/we1s-tools-and-software/topic-model-observatory/tmo-guide/tmo-guide-pyldavis/\n",
    "# A “relevance metric” slider scale at the top of the right panel controls how the words for a topic are sorted.\n",
    "# lambda 1: sorts words by their frequency in the topic (red bars)\n",
    "# lambda 0: sorts words by their \"lift\". Words whose red bars are nearly as long as their blue bars will be at the top Lift means how much a word's frequency sticks out in a topic above the baseline of its overall frequency in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
