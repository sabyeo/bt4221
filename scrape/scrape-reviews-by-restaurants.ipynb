{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 110.0.5481\n",
      "[WDM] - Get LATEST driver version for 110.0.5481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [/Users/natalie/.wdm/drivers/chromedriver/mac64/110.0.5481.77/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "browser = Chrome(ChromeDriverManager().install(), options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Collect All Reviews for a Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurant_details(browser): \n",
    "    page_html_pre_load_more = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    \n",
    "    name = page_html_pre_load_more.find(class_=\"venue-name\").text\n",
    "    name = name.replace('\\n', '')\n",
    "\n",
    "    num_reviews = page_html_pre_load_more.find(class_=\"venue-count-reviews\").text\n",
    "    num_reviews = int(num_reviews.split('\\n\\n')[1].split(' Review')[0])\n",
    "\n",
    "    neighbourhood = page_html_pre_load_more.find(class_=\"venue-area\").text\n",
    "    neighbourhood = neighbourhood.replace('\\n', '')\n",
    "\n",
    "    price = page_html_pre_load_more.find(class_=\"venue-price\").text\n",
    "    price = price.replace('\\n', '')\n",
    "\n",
    "    categories_html = page_html_pre_load_more.find_all(class_=\"venue-tag\")\n",
    "    categories = []\n",
    "    for category_html in categories_html:\n",
    "        categories.append(category_html.text)\n",
    "    \n",
    "    return name, num_reviews, neighbourhood, price, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurant_reviews_per_page(browser, reviews_by_restaurant, url, name, neighbourhood, price, categories): # function to load reviews for each page    \n",
    "    # find all reviews for each restaurant\n",
    "    page_html = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    all_reviews = page_html.findAll(class_=\"food card feed-item\")\n",
    "\n",
    "    for review_listing in all_reviews:\n",
    "        # review\n",
    "        review = review_listing.find(class_=\"food-description\").text\n",
    "\n",
    "        # user_card\n",
    "        user_card = review_listing.find(class_=\"food-user card-item\")\n",
    "        try:\n",
    "            user = user_card.find(class_=\"card-item-set--link-title\").text\n",
    "            user = user.replace('\\n', '')\n",
    "        except:\n",
    "            user = None\n",
    "        try:\n",
    "            date = user_card.find(class_=\"card-item-set--link-subtitle\").text\n",
    "            date = date.split('Â·')[0].replace('\\n', '')\n",
    "            # only take recent reviews, uptill 2020\n",
    "            if ('ago' in date) or ('at' in date) or (int(date.split(', ')[-1]) >=2020): \n",
    "                continue_loading = True\n",
    "            else:\n",
    "                continue_loading = False\n",
    "                break # no need to take remaining reviews in the page\n",
    "        except:\n",
    "            date = None\n",
    "            continue_loading = True\n",
    "\n",
    "        if continue_loading:\n",
    "            reviews_by_restaurant.append([url, name, neighbourhood, price, categories, review, user, date])\n",
    "    \n",
    "    return reviews_by_restaurant, continue_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_reviews(browser, url, name, neighbourhood, price, categories):\n",
    "    reviews_by_restaurant = []\n",
    "    continue_loading = True\n",
    "\n",
    "    while continue_loading: # to check if need to continue to click load more\n",
    "        # for each page, collect review data\n",
    "        reviews_by_restaurant, continue_loading = get_restaurant_reviews_per_page(browser, reviews_by_restaurant, url, name, neighbourhood, price, categories)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        try:\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            more_reviews = WebDriverWait(browser, 10).until(\n",
    "                EC.element_to_be_clickable((By.ID, \"load-more-reviews\")))\n",
    "            more_reviews.send_keys(Keys.ENTER)\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            continue_loading = False\n",
    "            print(e)\n",
    "    \n",
    "    return reviews_by_restaurant\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Reviews for Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'restaurant-data/data_00.xlsx' ### CHANGE THIS\n",
    "restaurant_list = pd.read_excel(file_name, index_col=0, engine='openpyxl')['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TOO FEW ### Ya Kun Kaya Toast not collected. Only has 1 reviews\n",
      "### TOO FEW ### 511 Lor Mee not collected. Only has 5 reviews\n",
      "### TOO FEW ### McDonald's not collected. Only has 1 reviews\n",
      "### TOO FEW ### Tian Yu Tian Fish Head Steamboat not collected. Only has 7 reviews\n",
      "### TOO FEW ### Kiroi Freshly Baked Cheese Cake not collected. Only has 13 reviews\n"
     ]
    }
   ],
   "source": [
    "for url in restaurant_list:\n",
    "    browser.get(url)\n",
    "\n",
    "    name, num_reviews, neighbourhood, price, categories = get_restaurant_details(browser)\n",
    "    if (num_reviews > 20):\n",
    "        if (name[0:9] != \"[CLOSED] \"): # check if restaurant closed down\n",
    "            reviews_by_restaurant = get_all_reviews(browser, url, name, neighbourhood, price, categories)\n",
    "            reviews_by_restaurant_df = pd.DataFrame(reviews_by_restaurant, columns=['url', 'name', 'neighbourhood', 'price', 'categories', 'review', 'user', 'date'])\n",
    "            reviews_by_restaurant_df.to_csv('restaurant-data/section0/' + name + '_reviews.csv') ### CHANGE FOLDER TO YOUR SECTION\n",
    "            time.sleep(5) # sleep for each restaurant\n",
    "        else: \n",
    "            output_text = output_text + \"\\n\" + \"### CLOSED  ### \" + name\n",
    "            print(\"### CLOSED  ### \" + name)\n",
    "    else:\n",
    "        output_text = output_text + \"\\n\" + \"### TOO FEW ### \" + name + ' not collected. Only has ' + str(num_reviews) + ' reviews'\n",
    "        print(\"### TOO FEW ### \" + name + ' not collected. Only has ' + str(num_reviews) + ' reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"section0_errors.txt\", \"w\") as text_file: ### CHANGE FILE NAME\n",
    "    text_file.write(output_text)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
