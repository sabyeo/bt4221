{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Downloading: 100%|██████████| 8.82M/8.82M [00:00<00:00, 20.5MB/s]\n",
      "/var/folders/74/n55gd6gs38n5wj2k6hwrc_yc0000gn/T/ipykernel_51641/748855775.py:2: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = Chrome(ChromeDriverManager().install(), options=options)\n"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "browser = Chrome(ChromeDriverManager().install(), options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Collect All Reviews for a Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurant_details(browser): \n",
    "    page_html_pre_load_more = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    try:\n",
    "        name = page_html_pre_load_more.find(class_=\"venue-name\").text\n",
    "        name = name.replace('\\n', '')\n",
    "    except:\n",
    "        name = None\n",
    "    try:\n",
    "        num_reviews = page_html_pre_load_more.find(class_=\"venue-count-reviews\").text\n",
    "        num_reviews = int(num_reviews.split('\\n\\n')[1].split(' Review')[0])\n",
    "    except:\n",
    "        num_reviews = None\n",
    "    try:\n",
    "        neighbourhood = page_html_pre_load_more.find(class_=\"venue-area\").text\n",
    "        neighbourhood = neighbourhood.replace('\\n', '')\n",
    "    except:\n",
    "        neighbourhood = None\n",
    "\n",
    "    try:\n",
    "        price = page_html_pre_load_more.find(class_=\"venue-price\").text\n",
    "        price = price.replace('\\n', '')\n",
    "    except:\n",
    "        price = None\n",
    "    try:\n",
    "        categories_html = page_html_pre_load_more.find_all(class_=\"venue-tag\")\n",
    "        categories = []\n",
    "        for category_html in categories_html:\n",
    "            categories.append(category_html.text)\n",
    "    except:\n",
    "        categories = None\n",
    "    \n",
    "    return name, num_reviews, neighbourhood, price, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurant_reviews_per_page(browser, reviews_by_restaurant, url, name, neighbourhood, price, categories): # function to load reviews for each page    \n",
    "    # find all reviews for each restaurant\n",
    "    page_html = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    all_reviews = page_html.findAll(class_=\"food card feed-item\")\n",
    "\n",
    "    for review_listing in all_reviews:\n",
    "        # review\n",
    "        review = review_listing.find(class_=\"food-description\").text\n",
    "\n",
    "        # user_card\n",
    "        user_card = review_listing.find(class_=\"food-user card-item\")\n",
    "        try:\n",
    "            user = user_card.find(class_=\"card-item-set--link-title\").text\n",
    "            user = user.replace('\\n', '')\n",
    "        except:\n",
    "            user = None\n",
    "        try:\n",
    "            date = user_card.find(class_=\"card-item-set--link-subtitle\").text\n",
    "            date = date.split('·')[0].replace('\\n', '')\n",
    "            # only take recent reviews, uptill 2020\n",
    "            if ('ago' in date) or ('at' in date) or (int(date.split(', ')[-1]) >=2020): \n",
    "                continue_loading = True\n",
    "            else:\n",
    "                continue_loading = False\n",
    "                break # no need to take remaining reviews in the page\n",
    "        except:\n",
    "            date = None\n",
    "            continue_loading = True\n",
    "\n",
    "        if continue_loading:\n",
    "            reviews_by_restaurant.append([url, name, neighbourhood, price, categories, review, user, date])\n",
    "    \n",
    "    return reviews_by_restaurant, continue_loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_reviews(browser, url, name, neighbourhood, price, categories):\n",
    "    reviews_by_restaurant = []\n",
    "    continue_loading = True\n",
    "\n",
    "    while continue_loading: # to check if need to continue to click load more\n",
    "        # for each page, collect review data\n",
    "        reviews_by_restaurant, continue_loading = get_restaurant_reviews_per_page(browser, reviews_by_restaurant, url, name, neighbourhood, price, categories)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        try:\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            more_reviews = WebDriverWait(browser, 10).until(\n",
    "                EC.element_to_be_clickable((By.ID, \"load-more-reviews\")))\n",
    "            more_reviews.send_keys(Keys.ENTER)\n",
    "            time.sleep(3)\n",
    "        except Exception as e:\n",
    "            continue_loading = False\n",
    "            print(e)\n",
    "    \n",
    "    return reviews_by_restaurant\n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Reviews for Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'restaurant-data/data_01.xlsx' ### CHANGE THIS\n",
    "restaurant_list = pd.read_excel(file_name, index_col=0, engine='openpyxl')['link']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### TOO FEW ### GOCHABAR (Funan) not collected. Only has 15 reviews\n",
      "### TOO FEW ### Greatly Blessed not collected. Only has 1 reviews\n",
      "### TOO FEW ### Jeffery's Corner not collected. Only has 1 reviews\n",
      "### TOO FEW ### Tian Fu Tea Room (UOB Plaza) not collected. Only has 9 reviews\n",
      "### TOO FEW ### Dough & Batter not collected. Only has 1 reviews\n",
      "### NO DETAILS, NO REVIEWS ### https://www.burpple.com/f/kN_WGi5b\n",
      "### TOO FEW ### Curry Puff House not collected. Only has 1 reviews\n",
      "### TOO FEW ### Big Mouth Eat (Havelock) not collected. Only has 5 reviews\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sabrina/Desktop/BZA/Y4S2/BT4221/bt4221/scrape/scrape-reviews-by-restaurants.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sabrina/Desktop/BZA/Y4S2/BT4221/bt4221/scrape/scrape-reviews-by-restaurants.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mif\u001b[39;00m (num_reviews \u001b[39m>\u001b[39m \u001b[39m20\u001b[39m) \u001b[39mand\u001b[39;00m num_reviews\u001b[39m!=\u001b[39m\u001b[39mNone\u001b[39;00m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sabrina/Desktop/BZA/Y4S2/BT4221/bt4221/scrape/scrape-reviews-by-restaurants.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mif\u001b[39;00m (name[\u001b[39m0\u001b[39m:\u001b[39m9\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m[CLOSED] \u001b[39m\u001b[39m\"\u001b[39m): \u001b[39m# check if restaurant closed down\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sabrina/Desktop/BZA/Y4S2/BT4221/bt4221/scrape/scrape-reviews-by-restaurants.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         reviews_by_restaurant \u001b[39m=\u001b[39m get_all_reviews(browser, url, name, neighbourhood, price, categories)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sabrina/Desktop/BZA/Y4S2/BT4221/bt4221/scrape/scrape-reviews-by-restaurants.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         reviews_by_restaurant_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(reviews_by_restaurant, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mneighbourhood\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprice\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcategories\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mreview\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdate\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sabrina/Desktop/BZA/Y4S2/BT4221/bt4221/scrape/scrape-reviews-by-restaurants.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         reviews_by_restaurant_df\u001b[39m.\u001b[39mto_csv(\u001b[39m'\u001b[39m\u001b[39mrestaurant-data/section1/\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_reviews.csv\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m### CHANGE FOLDER TO YOUR SECTION\u001b[39;00m\n",
      "\u001b[1;32m/Users/sabrina/Desktop/BZA/Y4S2/BT4221/bt4221/scrape/scrape-reviews-by-restaurants.ipynb Cell 11\u001b[0m in \u001b[0;36mget_all_reviews\u001b[0;34m(browser, url, name, neighbourhood, price, categories)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sabrina/Desktop/BZA/Y4S2/BT4221/bt4221/scrape/scrape-reviews-by-restaurants.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mwhile\u001b[39;00m continue_loading: \u001b[39m# to check if need to continue to click load more\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sabrina/Desktop/BZA/Y4S2/BT4221/bt4221/scrape/scrape-reviews-by-restaurants.ipynb#X26sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39m# for each page, collect review data\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sabrina/Desktop/BZA/Y4S2/BT4221/bt4221/scrape/scrape-reviews-by-restaurants.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     reviews_by_restaurant, continue_loading \u001b[39m=\u001b[39m get_restaurant_reviews_per_page(browser, reviews_by_restaurant, url, name, neighbourhood, price, categories)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sabrina/Desktop/BZA/Y4S2/BT4221/bt4221/scrape/scrape-reviews-by-restaurants.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m2\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sabrina/Desktop/BZA/Y4S2/BT4221/bt4221/scrape/scrape-reviews-by-restaurants.ipynb#X26sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/sabrina/Desktop/BZA/Y4S2/BT4221/bt4221/scrape/scrape-reviews-by-restaurants.ipynb#X26sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         browser\u001b[39m.\u001b[39mexecute_script(\u001b[39m\"\u001b[39m\u001b[39mwindow.scrollTo(0, document.body.scrollHeight);\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for url in restaurant_list:\n",
    "    browser.get(url)\n",
    "    time.sleep(5) # sleep for each restaurant\n",
    "\n",
    "    name, num_reviews, neighbourhood, price, categories = get_restaurant_details(browser)\n",
    "    if num_reviews != None:\n",
    "        if (num_reviews > 20) and num_reviews!=None:\n",
    "            if (name[0:9] != \"[CLOSED] \"): # check if restaurant closed down\n",
    "                reviews_by_restaurant = get_all_reviews(browser, url, name, neighbourhood, price, categories)\n",
    "                reviews_by_restaurant_df = pd.DataFrame(reviews_by_restaurant, columns=['url', 'name', 'neighbourhood', 'price', 'categories', 'review', 'user', 'date'])\n",
    "                reviews_by_restaurant_df.to_csv('restaurant-data/section1/' + name + '_reviews.csv') ### CHANGE FOLDER TO YOUR SECTION\n",
    "                time.sleep(3)\n",
    "            else: \n",
    "                output_text = output_text + \"\\n\" + \"### CLOSED  ### \" + name\n",
    "                print(\"### CLOSED  ### \" + name)\n",
    "        else:\n",
    "            output_text = output_text + \"\\n\" + \"### TOO FEW ### \" + name + ' not collected. Only has ' + str(num_reviews) + ' reviews'\n",
    "            print(\"### TOO FEW ### \" + name + ' not collected. Only has ' + str(num_reviews) + ' reviews')\n",
    "    else:\n",
    "        output_text = output_text + \"\\n\" + \"### NO DETAILS, NO REVIEWS ### \"+ url\n",
    "        print(\"### NO DETAILS, NO REVIEWS ### \"+ url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"section1_errors.txt\", \"w\") as text_file: ### CHANGE FILE NAME\n",
    "    text_file.write(output_text)\n",
    "    text_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
