{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = Options()\n",
    "browser = Chrome(ChromeDriverManager().install(), options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Collect All Reviews for a Restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurant_details(browser): \n",
    "    page_html_pre_load_more = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    \n",
    "    name = page_html_pre_load_more.find(class_=\"venue-name\").text\n",
    "    name = name.replace('\\n', '')\n",
    "\n",
    "    num_reviews = page_html_pre_load_more.find(class_=\"venue-count-reviews\").text\n",
    "    num_reviews = int(num_reviews.split('\\n\\n')[1].split(' Reviews')[0])\n",
    "\n",
    "    neighbourhood = page_html_pre_load_more.find(class_=\"venue-area\").text\n",
    "    neighbourhood = neighbourhood.replace('\\n', '')\n",
    "\n",
    "    price = page_html_pre_load_more.find(class_=\"venue-price\").text\n",
    "    price = price.replace('\\n', '')\n",
    "\n",
    "    categories_html = page_html_pre_load_more.find_all(class_=\"venue-tag\")\n",
    "    categories = []\n",
    "    for category_html in categories_html:\n",
    "        categories.append(category_html.text)\n",
    "    \n",
    "    return name, num_reviews, neighbourhood, price, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_reviews(browser):\n",
    "    load_more = True\n",
    "    page_count = 0\n",
    "    while load_more:\n",
    "        if page_count == 5:\n",
    "            break\n",
    "        try:\n",
    "            browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            more_reviews = WebDriverWait(browser, 10).until(\n",
    "                EC.element_to_be_clickable((By.ID, \"load-more-reviews\")))\n",
    "            more_reviews.send_keys(Keys.ENTER)\n",
    "            time.sleep(3)\n",
    "            page_count +=1\n",
    "        except Exception as e:\n",
    "            load_more = False\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_restaurant_reviews(browser, url, name, num_reviews, neighbourhood, price, categories):\n",
    "    load_all_reviews(browser)\n",
    "    \n",
    "    # find all reviews for each restaurant\n",
    "    page_html = BeautifulSoup(browser.page_source, \"html.parser\")\n",
    "    all_reviews = page_html.findAll(class_=\"food card feed-item\")\n",
    "    \n",
    "    if len(all_reviews) != num_reviews:\n",
    "        print(\"### DIFF NUM ###: \" + str(len(all_reviews)) + ' out of ' + str(num_reviews) + ' reviews collected.')\n",
    "\n",
    "    reviews_by_restaurant = []\n",
    "    for review_listing in all_reviews:\n",
    "        # review\n",
    "        review = review_listing.find(class_=\"food-description\").text\n",
    "\n",
    "        # user_card\n",
    "        user_card = review_listing.find(class_=\"food-user card-item\")\n",
    "        try:\n",
    "            user = user_card.find(class_=\"card-item-set--link-title\").text\n",
    "            user = user.replace('\\n', '')\n",
    "        except:\n",
    "            user = None\n",
    "        try:\n",
    "            date = user_card.find(class_=\"card-item-set--link-subtitle\").text\n",
    "            date = date.split('Â·')[0].replace('\\n', '')\n",
    "        except:\n",
    "            date = None\n",
    "\n",
    "        reviews_by_restaurant.append([url, name, neighbourhood, price, categories, review, user, date])\n",
    "    \n",
    "    return reviews_by_restaurant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Reviews for Restaurants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'restaurant_links_0.csv' ### CHANGE THIS\n",
    "restaurant_list = pd.read_csv(file_name, index_col=0)['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for url in restaurant_list:\n",
    "    browser.get(url)\n",
    "    time.sleep(5) # sleep for each restaurant\n",
    "\n",
    "    name, num_reviews, neighbourhood, price, categories = get_restaurant_details(browser)\n",
    "    if (num_reviews > 50):\n",
    "        if (name[0:9] != \"[CLOSED] \"):\n",
    "            reviews_by_restaurant = get_restaurant_reviews(browser, url, name, num_reviews, neighbourhood, price, categories)\n",
    "            reviews_by_restaurant_df = pd.DataFrame(reviews_by_restaurant, columns=['url', 'name', 'neighbourhood', 'price', 'categories', 'review', 'user', 'date'])\n",
    "            reviews_by_restaurant_df.to_csv('restaurant-data/' + name + '_reviews.csv')\n",
    "        else: \n",
    "            print(\"### CLOSED   ### \" + name)\n",
    "    else:\n",
    "        print(\"### TOO FEW  ### \" + name + ' not collected. Only has ' + str(num_reviews) + ' reviews')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
