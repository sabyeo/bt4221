{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "import os\n",
    "import numpy as np\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('scrape/restaurant-data/cleaned_restaurant_reviews.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restaurant_review_df = data[['url', 'cleaned_text']]\n",
    "# restaurant_review_df = restaurant_review_df.groupby(['url'], as_index = False).agg({'cleaned_text': ' '.join})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary\n",
    "docs = data['cleaned_text'] ###\n",
    "processed_docs = [d.split() for d in docs]\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# term document frequency\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
    "                                       id2word=dictionary,\n",
    "                                       num_topics=10,\n",
    "                                       alpha=0.1, # document topic density. higher alpha, documents composed of more topics\n",
    "                                       eta=0.01, # topic word density. higher beta, topics composed of large number of words in the corpus\n",
    "                                       chunksize=100, # number of documents to consider at once\n",
    "                                       passes=10, # number of times to go through the entire corpus\n",
    "                                       random_state =100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.014*\"food\" + 0.009*\"menu\" + 0.009*\"dish\" + 0.009*\"place\" + 0.008*\"set\" + '\n",
      "  '0.008*\"time\" + 0.007*\"good\" + 0.007*\"restaurant\" + 0.007*\"try\" + '\n",
      "  '0.006*\"come\"'),\n",
      " (1,\n",
      "  '0.034*\"beef\" + 0.023*\"food\" + 0.021*\"great\" + 0.021*\"good\" + 0.014*\"try\" + '\n",
      "  '0.013*\"recommend\" + 0.013*\"rib\" + 0.013*\"steak\" + 0.012*\"place\" + '\n",
      "  '0.011*\"tender\"'),\n",
      " (2,\n",
      "  '0.046*\"egg\" + 0.019*\"pasta\" + 0.018*\"bread\" + 0.018*\"good\" + 0.016*\"toast\" '\n",
      "  '+ 0.012*\"salmon\" + 0.011*\"taste\" + 0.011*\"breakfast\" + 0.010*\"dish\" + '\n",
      "  '0.010*\"sauce\"'),\n",
      " (3,\n",
      "  '0.017*\"flavour\" + 0.014*\"sweet\" + 0.013*\"sauce\" + 0.008*\"savoury\" + '\n",
      "  '0.008*\"rice\" + 0.008*\"serve\" + 0.008*\"fish\" + 0.007*\"dish\" + '\n",
      "  '0.007*\"restaurant\" + 0.007*\"singapore\"'),\n",
      " (4,\n",
      "  '0.021*\"delivery\" + 0.021*\"singapore\" + 0.021*\"available\" + '\n",
      "  '0.019*\"cheesecake\" + 0.017*\"new\" + 0.015*\"cake\" + 0.013*\"takeaway\" + '\n",
      "  '0.011*\"burnt\" + 0.011*\"durian\" + 0.010*\"menu\"'),\n",
      " (5,\n",
      "  '0.036*\"chicken\" + 0.029*\"fry\" + 0.026*\"rice\" + 0.020*\"pork\" + 0.019*\"sauce\" '\n",
      "  '+ 0.016*\"dish\" + 0.013*\"meat\" + 0.012*\"crispy\" + 0.011*\"fish\" + '\n",
      "  '0.009*\"spicy\"'),\n",
      " (6,\n",
      "  '0.033*\"cream\" + 0.021*\"chocolate\" + 0.019*\"sweet\" + 0.018*\"ice\" + '\n",
      "  '0.012*\"flavour\" + 0.012*\"tart\" + 0.011*\"croissant\" + 0.011*\"cake\" + '\n",
      "  '0.010*\"tea\" + 0.009*\"dessert\"'),\n",
      " (7,\n",
      "  '0.039*\"cheese\" + 0.028*\"burger\" + 0.022*\"truffle\" + 0.017*\"fry\" + '\n",
      "  '0.017*\"pizza\" + 0.013*\"mushroom\" + 0.013*\"bun\" + 0.013*\"potato\" + '\n",
      "  '0.012*\"onion\" + 0.011*\"tomato\"'),\n",
      " (8,\n",
      "  '0.046*\"noodle\" + 0.041*\"prawn\" + 0.040*\"soup\" + 0.019*\"broth\" + '\n",
      "  '0.016*\"bowl\" + 0.014*\"mee\" + 0.014*\"ramen\" + 0.014*\"seafood\" + 0.013*\"pork\" '\n",
      "  '+ 0.010*\"lobster\"'),\n",
      " (9,\n",
      "  '0.021*\"taste\" + 0.020*\"like\" + 0.014*\"good\" + 0.012*\"matcha\" + 0.012*\"try\" '\n",
      "  '+ 0.011*\"flavour\" + 0.010*\"coffee\" + 0.009*\"tea\" + 0.009*\"quite\" + '\n",
      "  '0.009*\"sweet\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "lda_score = coherence_model_lda.get_coherence()\n",
    "lda_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(k):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k,\n",
    "                                           alpha=0.1, # document topic density. higher alpha, documents composed of more topics\n",
    "                                           eta=0.01, # topic word density. higher beta, topics composed of large number of words in the corpus\n",
    "                                           chunksize=100, # number of documents to consider at once\n",
    "                                           passes=10, # number of times to go through the entire corpus\n",
    "                                           random_state =100)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=processed_docs, dictionary=dictionary, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid = {}\n",
    "# grid['Validation_Set'] = {}\n",
    "\n",
    "# # Topics range\n",
    "# min_topics = 2\n",
    "# max_topics = 11\n",
    "# step_size = 1\n",
    "# topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# # Alpha parameter\n",
    "# alpha = list(np.arange(0.01, 1, 0.3))\n",
    "# alpha.append('symmetric')\n",
    "# alpha.append('asymmetric')\n",
    "\n",
    "# # Beta parameter\n",
    "# beta = list(np.arange(0.01, 1, 0.3))\n",
    "# beta.append('symmetric')\n",
    "\n",
    "\n",
    "# model_results = {\n",
    "#                  'Topics': [],\n",
    "#                  'Alpha': [],\n",
    "#                  'Beta': [],\n",
    "#                  'Coherence': []\n",
    "#                 }\n",
    "\n",
    "# # Can take a long time to run\n",
    "# if 1 == 1:\n",
    "#     pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)))\n",
    "    \n",
    "#     # iterate through number of topics\n",
    "#     for k in topics_range:\n",
    "#         # iterate through alpha values\n",
    "#         for a in alpha:\n",
    "#             # iterare through beta values\n",
    "#             for b in beta:\n",
    "#                 # get the coherence score for the given parameters\n",
    "#                 cv = compute_coherence_values(k=k, a=a, b=b)\n",
    "#                 # Save the model results\n",
    "#                 model_results['Topics'].append(k)\n",
    "#                 model_results['Alpha'].append(a)\n",
    "#                 model_results['Beta'].append(b)\n",
    "#                 model_results['Coherence'].append(cv)\n",
    "                \n",
    "#                 pbar.update(1)\n",
    "#     pd.DataFrame(model_results).to_csv('restaurant_lda_tuning_results.csv', index=False)\n",
    "#     pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate through number of topics\n",
    "coherence_values = []\n",
    "topics_range = range(2,11,1)\n",
    "\n",
    "for k in topics_range:\n",
    "    value = compute_coherence_values(k)\n",
    "    print(k)\n",
    "    print(value)\n",
    "    coherence_values.append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Show graph\n",
    "plt.plot(topics_range, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal parameters\n",
    "num_topics = 4\n",
    "alpha = \n",
    "beta = \n",
    "\n",
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=bow_corpus,\n",
    "                                        id2word=dictionary,\n",
    "                                        num_topics=num_topics,\n",
    "                                        alpha=alpha, # document topic density. higher alpha, documents composed of more topics\n",
    "                                        eta=beta, # topic word density. higher beta, topics composed of large number of words in the corpus\n",
    "                                        chunksize=100, # number of documents to consider at once\n",
    "                                        passes=10, # number of times to go through the entire corpus\n",
    "                                        random_state =100)\n",
    "# Print the Keyword in the topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('restaurant_ldavis_prepared_'+str(num_topics)+'_'+str(a))\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model, bow_corpus, dictionary)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, 'restaurant_ldavis_prepared_'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
